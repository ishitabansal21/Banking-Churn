{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Impact to SVM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run two SVM models, one without using SMOTE and the other one with SMOTE.\n",
    "\n",
    "We are interested to see what kind of impact SMOTE could introduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# store elements as dictionary keys and their counts as dictionary values\n",
    "from collections import Counter\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Function for creating model pipelines - sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Function for creating model pipelines - imblearn\n",
    "from imblearn.pipeline import make_pipeline as imbl_pipe\n",
    "\n",
    "# Over-sampling using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Analytical Base Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (10000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\"../Resources\", \"analytical_base_table.csv\"))\n",
    "print(f\"Dataframe dimensions: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate dataframe into separate object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Object for target variable\n",
    "y = df.Exited\n",
    "\n",
    "# object for input features\n",
    "X = df.drop(['Exited'], axis=1)\n",
    "\n",
    "# display shapes of X and y\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List numerical features\n",
    "num_columns = X.select_dtypes(include='number').columns.tolist()\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geography', 'Gender']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List categorical features\n",
    "cat_columns = X.select_dtypes(include='object').columns.tolist()\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_count(a):\n",
    "    counter=Counter(a)\n",
    "    kv=[list(counter.keys()),list(counter.values())]\n",
    "    dff = pd.DataFrame(np.array(kv).T, columns=['Exited','Count'])\n",
    "    dff['Count'] = dff['Count'].astype('int64')\n",
    "    dff['%'] = round(dff['Count'] / a.shape[0] * 100, 2)\n",
    "    return dff.sort_values('Count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exited</th>\n",
       "      <th>Count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7963</td>\n",
       "      <td>79.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2037</td>\n",
       "      <td>20.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Exited  Count      %\n",
       "1       0   7963  79.63\n",
       "0       1   2037  20.37"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 3000 7000 3000\n"
     ]
    }
   ],
   "source": [
    "random_state = 10\n",
    "\n",
    "# Split X and y into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=random_state,\n",
    "                                                   stratify=df.Exited)\n",
    "\n",
    "# Print number of observations in X_train, X_test, y_train, and y_test\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7000 entries, 8061 to 4741\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      7000 non-null   int64  \n",
      " 1   Geography        7000 non-null   object \n",
      " 2   Gender           7000 non-null   object \n",
      " 3   Age              7000 non-null   int64  \n",
      " 4   Tenure           7000 non-null   int64  \n",
      " 5   Balance          7000 non-null   float64\n",
      " 6   NumOfProducts    7000 non-null   int64  \n",
      " 7   HasCrCard        7000 non-null   int64  \n",
      " 8   IsActiveMember   7000 non-null   int64  \n",
      " 9   EstimatedSalary  7000 non-null   float64\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 601.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale numerical data and encode categorical data\n",
    "Construct a pre-processing pipeline from the given transformers: MinMaxScaler and OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists of indexes from the list of column names\n",
    "\n",
    "Need to be numeric not string to specify columns name in column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "num_features = [] \n",
    "\n",
    "for i in num_columns:\n",
    "    location = X.columns.get_loc(i)\n",
    "    num_features.append(location)\n",
    "print(num_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "cat_features = []\n",
    "\n",
    "for i in cat_columns:\n",
    "    location = X.columns.get_loc(i)\n",
    "    cat_features.append(location)\n",
    "print(cat_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                ('onehotencoder', OneHotEncoder(sparse=False),\n",
       "                                 [1, 2])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define column transformer\n",
    "# Need to be numeric not string to specify columns name \n",
    "preprocess = make_column_transformer(\n",
    "    (MinMaxScaler(), num_features),\n",
    "    (OneHotEncoder(sparse=False), cat_features)\n",
    ")\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model Pipeline without SMOTE\n",
    "\n",
    "* To see the impact of SMOTE to our results, wew will first build our pipeline without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('minmaxscaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [1, 2])])),\n",
       "                ('svc', SVC(random_state=10))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import classifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "# Define model with pipeline\n",
    "model = imbl_pipe(preprocess,\n",
    "                  SVC(random_state=random_state))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'svc__kernel' : ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "              'svc__C': [0.0005,0.001, 0.01, 0.1, 0.5],\n",
    "              'svc__gamma': [5, 1, 0.1, 0.01]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3, cv= 5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('minmaxscaler',\n",
       "                                                                         MinMaxScaler(),\n",
       "                                                                         [0, 3,\n",
       "                                                                          4, 5,\n",
       "                                                                          6, 7,\n",
       "                                                                          8,\n",
       "                                                                          9]),\n",
       "                                                                        ('onehotencoder',\n",
       "                                                                         OneHotEncoder(sparse=False),\n",
       "                                                                         [1,\n",
       "                                                                          2])])),\n",
       "                                       ('svc', SVC(random_state=10))]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'svc__C': [0.0005, 0.001, 0.01, 0.1, 0.5],\n",
       "                         'svc__gamma': [5, 1, 0.1, 0.01],\n",
       "                         'svc__kernel': ['linear', 'rbf', 'poly', 'sigmoid']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 0.5, 'svc__gamma': 5, 'svc__kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8554285714285713\n"
     ]
    }
   ],
   "source": [
    " # List the best score\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8748571428571429\n",
      "Testing Data Score: 0.865\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {grid.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2312   77]\n",
      " [ 328  283]]\n"
     ]
    }
   ],
   "source": [
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97 0.03]\n",
      " [0.54 0.46]]\n"
     ]
    }
   ],
   "source": [
    "cm = np.around(cm / cm.sum(axis=1)[:, np.newaxis], 2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      2389\n",
      "           1       0.79      0.46      0.58       611\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.83      0.72      0.75      3000\n",
      "weighted avg       0.86      0.86      0.85      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [0]\n",
      "Actual Labels: [1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {pred}\")\n",
    "print(f\"Actual Labels: {list(y_test[:1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model Pipeline with SMOTE\n",
    "\n",
    "* Let's check now the impact of SMOTE to our results\n",
    "\n",
    "* We are going to use the Pipeline from the imblearn package in place of scikit-learn Pipeline.\n",
    "\n",
    "* It takes care automatically to re-sample when called fit() on the pipeline, and does not re-sample test data (when called transform() or predict())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('minmaxscaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [1, 2])])),\n",
       "                ('smote', SMOTE(random_state=10)),\n",
       "                ('svc', SVC(random_state=10))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import classifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "# Define model with pipeline\n",
    "model_s = imbl_pipe(preprocess,\n",
    "                  SMOTE(sampling_strategy='auto', random_state=random_state),\n",
    "                  SVC(random_state=random_state))\n",
    "\n",
    "model_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'svc__kernel' : ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "              'svc__C': [0.0005,0.001, 0.01, 0.1, 0.5],\n",
    "              'svc__gamma': [5, 1, 0.1, 0.01]}\n",
    "grid_s = GridSearchCV(model_s, param_grid, verbose=3, cv= 5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model with GridSearch\n",
    "grid_s.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_s.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # List the best score\n",
    "print(grid_s.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {grid_s.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {grid_s.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions_s = grid_s.predict(X_test)\n",
    "predictions_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions_s)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.around(cm / cm.sum(axis=1)[:, np.newaxis], 2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_s = grid.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Predicted classes: {pred_s}\")\n",
    "print(f\"Actual Labels: {list(y_test[:1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# We are saving our grid model\n",
    "filename_nos = '../models/SVM_model_nos.sav'\n",
    "joblib.dump(grid, filename_nos)\n",
    "filename_s = '../models/SVM_model_s.sav'\n",
    "joblib.dump(grid_s, filename_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models\n",
    "svm_model_nos = joblib.load(filename_nos)\n",
    "print(svm_model_nos.score(X_test, y_test))\n",
    "\n",
    "svm_model_s = joblib.load(filename_s)\n",
    "print(svm_model_s.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
