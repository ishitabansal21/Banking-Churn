{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# store elements as dictionary keys and their counts as dictionary values\n",
    "from collections import Counter\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Function for creating model pipelines - sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Function for creating model pipelines - imblearn\n",
    "from imblearn.pipeline import make_pipeline as imbl_pipe\n",
    "\n",
    "# Over-sampling using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Analytical Base Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (10000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\"../Resources\", \"analytical_base_table.csv\"))\n",
    "print(f\"Dataframe dimensions: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate dataframe into separate object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Object for target variable\n",
    "y = df.Exited\n",
    "\n",
    "# object for input features\n",
    "X = df.drop(['Exited'], axis=1)\n",
    "\n",
    "# display shapes of X and y\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List numerical features\n",
    "num_columns = X.select_dtypes(include='number').columns.tolist()\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geography', 'Gender']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List categorical features\n",
    "cat_columns = X.select_dtypes(include='object').columns.tolist()\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_count(a):\n",
    "    counter=Counter(a)\n",
    "    kv=[list(counter.keys()),list(counter.values())]\n",
    "    dff = pd.DataFrame(np.array(kv).T, columns=['Exited','Count'])\n",
    "    dff['Count'] = dff['Count'].astype('int64')\n",
    "    dff['%'] = round(dff['Count'] / a.shape[0] * 100, 2)\n",
    "    return dff.sort_values('Count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exited</th>\n",
       "      <th>Count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7963</td>\n",
       "      <td>79.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2037</td>\n",
       "      <td>20.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Exited  Count      %\n",
       "1       0   7963  79.63\n",
       "0       1   2037  20.37"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 3000 7000 3000\n"
     ]
    }
   ],
   "source": [
    "random_state = 10\n",
    "\n",
    "# Split X and y into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=random_state,\n",
    "                                                   stratify=df.Exited)\n",
    "\n",
    "# Print number of observations in X_train, X_test, y_train, and y_test\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7000 entries, 8061 to 4741\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      7000 non-null   int64  \n",
      " 1   Geography        7000 non-null   object \n",
      " 2   Gender           7000 non-null   object \n",
      " 3   Age              7000 non-null   int64  \n",
      " 4   Tenure           7000 non-null   int64  \n",
      " 5   Balance          7000 non-null   float64\n",
      " 6   NumOfProducts    7000 non-null   int64  \n",
      " 7   HasCrCard        7000 non-null   int64  \n",
      " 8   IsActiveMember   7000 non-null   int64  \n",
      " 9   EstimatedSalary  7000 non-null   float64\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 601.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale numerical data and encode categorical data\n",
    "Construct a pre-processing pipeline from the given transformers: MinMaxScaler and OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists of indexes from the list of column names\n",
    "\n",
    "Need to be numeric not string to specify columns name in column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "num_features = [] \n",
    "\n",
    "for i in num_columns:\n",
    "    location = X.columns.get_loc(i)\n",
    "    num_features.append(location)\n",
    "print(num_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "cat_features = []\n",
    "\n",
    "for i in cat_columns:\n",
    "    location = X.columns.get_loc(i)\n",
    "    cat_features.append(location)\n",
    "print(cat_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                ('onehotencoder', OneHotEncoder(sparse=False),\n",
       "                                 [1, 2])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define column transformer\n",
    "# Need to be numeric not string to specify columns name \n",
    "preprocess = make_column_transformer(\n",
    "    (MinMaxScaler(), num_features),\n",
    "    (OneHotEncoder(sparse=False), cat_features)\n",
    ")\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model Pipeline with SMOTE\n",
    "\n",
    "* We are going to use the Pipeline from the imblearn package in place of scikit-learn Pipeline.\n",
    "\n",
    "* It takes care automatically to re-sample when called fit() on the pipeline, and does not re-sample test data (when called transform() or predict())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('minmaxscaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [1, 2])])),\n",
       "                ('smote', SMOTE(random_state=10)),\n",
       "                ('svc', SVC(random_state=10))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import classifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "# Define model with pipeline\n",
    "model = imbl_pipe(preprocess,\n",
    "                  SMOTE(sampling_strategy='auto', random_state=random_state),\n",
    "                  SVC(random_state=random_state))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'svc__kernel' : ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "              'svc__C': [0.0005,0.001, 0.01, 0.1, 0.5],\n",
    "              'svc__gamma': [5, 1, 0.1, 0.01]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3, cv= 5, n_jobs=4, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))  # Should print: <class 'pandas.core.frame.DataFrame'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # List the best score\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {grid.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "scores = [grid.score(X_train, y_train) * 100, grid.score(X_test, y_test) * 100]\n",
    "labels = ['Training Data', 'Testing Data']\n",
    "\n",
    "# Create a figure with smaller size\n",
    "plt.figure(figsize=(6, 2))  # Adjust the width and height as needed\n",
    "\n",
    "# Plot with pastel pink color for the line\n",
    "plt.plot(labels, scores, marker='o', color='#F7934C', linestyle='-', linewidth=3, markersize=8)\n",
    "\n",
    "# Set the Y-axis limits to center the line\n",
    "plt.ylim(min(scores) - 10, max(scores) + 10)  # Adjust this to make sure the line is centered within the plot\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model Accuracy: Training vs Testing')\n",
    "\n",
    "# Adding the text on the plot\n",
    "for i in range(len(scores)):\n",
    "    plt.text(labels[i], scores[i] + 2, f'{int(scores[i])}%', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.around(cm / cm.sum(axis=1)[:, np.newaxis], 2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Example normalized confusion matrix\n",
    "cm = np.array([[0.83, 0.17], \n",
    "               [0.32, 0.68]])\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap=sns.light_palette(\"#F7934C\", as_cmap=True), cbar=False)\n",
    "\n",
    "# Add labels, title, and axes\n",
    "plt.title('Normalized Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['Class 0', 'Class 1'], fontsize=10)\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['Class 0', 'Class 1'], fontsize=10, rotation=0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Sample classification report data\n",
    "report = classification_report(y_test, predictions, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, and f1-score for each class\n",
    "precision_class_0 = report['0']['precision']\n",
    "recall_class_0 = report['0']['recall']\n",
    "f1_class_0 = report['0']['f1-score']\n",
    "\n",
    "precision_class_1 = report['1']['precision']\n",
    "recall_class_1 = report['1']['recall']\n",
    "f1_class_1 = report['1']['f1-score']\n",
    "\n",
    "# Set up the positions for each bar\n",
    "metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "class_0_values = [precision_class_0, recall_class_0, f1_class_0]\n",
    "class_1_values = [precision_class_1, recall_class_1, f1_class_1]\n",
    "\n",
    "# Bar colors\n",
    "class_0_color = '#F7934C'  # Purple for class 0\n",
    "class_1_color = '#A5B452'  # Olive for class 1\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create horizontal bars\n",
    "bar_width = 0.2  # Reduced width of bars\n",
    "index = np.arange(len(metrics))  # Position for each metric\n",
    "\n",
    "# Plot bars for class 0 and class 1, side by side\n",
    "bars_class_0 = plt.barh(index - bar_width / 2, class_0_values, bar_width, label='Customers who did not churn.', color=class_0_color)\n",
    "bars_class_1 = plt.barh(index + bar_width / 2, class_1_values, bar_width, label='Customers who did churn.', color=class_1_color)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Score')\n",
    "plt.title('Classification Report: Precision, Recall, F1-Score by Class')\n",
    "plt.yticks(index, metrics)  # Set y-axis to show metrics\n",
    "plt.legend()\n",
    "\n",
    "# Adding text labels for the values on top of the bars\n",
    "for i, bar in enumerate(bars_class_0):\n",
    "    # Add value for class 0\n",
    "    plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height() / 2, \n",
    "             f'{class_0_values[i]:.2f}', va='center', ha='left', fontsize=12, color='black')\n",
    "\n",
    "for i, bar in enumerate(bars_class_1):\n",
    "    # Add value for class 1\n",
    "    plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height() / 2, \n",
    "             f'{class_1_values[i]:.2f}', va='center', ha='left', fontsize=12, color='black')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predicted classes: {pred}\")\n",
    "print(f\"Actual Labels: {list(y_test[:1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# We are saving our grid model\n",
    "filename = '../models/SVM_model.sav'\n",
    "joblib.dump(grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "svm_model = joblib.load(filename)\n",
    "print(svm_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict class for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the first X_test record as new data\n",
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new = grid.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Predicted classes: {pred_new}\")\n",
    "print(f\"Actual Labels: {list(y_test[:1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set probability=True to enable predict_proba\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "# Train your model (assuming grid is your grid search object)\n",
    "grid = GridSearchCV(svc, param_grid, cv=5)  # Make sure to define your param_grid\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set probability=True to enable predict_proba\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "# Train your model (assuming grid is your grid search object)\n",
    "grid = GridSearchCV(svc, param_grid, cv=5)  # Define your param_grid accordingly\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class (class 1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, grid.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Calculate AUC (Area Under the Curve)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='#F7934C', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='#60435F', lw=2, linestyle='--')  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - SVC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Predict probabilities for the positive class (class 1)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m precision, recall, _ \u001b[38;5;241m=\u001b[39m precision_recall_curve(y_test, \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(X_test)[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate the Average Precision (AUC)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m pr_auc \u001b[38;5;241m=\u001b[39m average_precision_score(y_test, grid\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\Bank-Churn-Prediction\\server\\venv\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:109\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m    103\u001b[0m attr_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(owner\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m )\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n",
      "File \u001b[1;32m~\\Bank-Churn-Prediction\\server\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:373\u001b[0m, in \u001b[0;36m_estimator_has.<locals>.check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    370\u001b[0m _check_refit(\u001b[38;5;28mself\u001b[39m, attr)\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_estimator_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;66;03m# raise an AttributeError if `attr` does not exist\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# raise an AttributeError if `attr` does not exist\u001b[39;00m\n",
      "File \u001b[1;32m~\\Bank-Churn-Prediction\\server\\venv\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:109\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m    103\u001b[0m attr_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(owner\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m )\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n",
      "File \u001b[1;32m~\\Bank-Churn-Prediction\\server\\venv\\lib\\site-packages\\sklearn\\pipeline.py:45\u001b[0m, in \u001b[0;36m_final_estimator_has.<locals>.check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# raise original `AttributeError` if `attr` does not exist\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Bank-Churn-Prediction\\server\\venv\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:109\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m    103\u001b[0m attr_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(owner\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m )\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n",
      "File \u001b[1;32m~\\Bank-Churn-Prediction\\server\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:800\u001b[0m, in \u001b[0;36mBaseSVC._check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability:\n\u001b[1;32m--> 800\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba is not available when  probability=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    802\u001b[0m         )\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnu_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    804\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba only implemented for SVC and NuSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict probabilities for the positive class (class 1)\n",
    "precision, recall, _ = precision_recall_curve(y_test, grid.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Calculate the Average Precision (AUC)\n",
    "pr_auc = average_precision_score(y_test, grid.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='#F7934C', lw=2, label='PR curve (AUC = %0.2f)' % pr_auc)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - SVC')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "coef_ is only available when using a linear kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Call the function with necessary arguments\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[43mplot_feature_importance_svm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[84], line 30\u001b[0m, in \u001b[0;36mplot_feature_importance_svm\u001b[1;34m(model, original_num_features, original_cat_features, X_train)\u001b[0m\n\u001b[0;32m     27\u001b[0m all_feature_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([num_feature_names, cat_feature_names])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Extract coefficients from the SVM model (for linear SVM only)\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m coefficients \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43msvm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Normalize importance to percentage\u001b[39;00m\n\u001b[0;32m     33\u001b[0m importance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m (coefficients \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(coefficients))\n",
      "File \u001b[1;32m~\\Bank-Churn-Prediction\\server\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:637\u001b[0m, in \u001b[0;36mBaseLibSVM.coef_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Weights assigned to the features when `kernel=\"linear\"`.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03mReturns\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;124;03m-------\u001b[39;00m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;124;03mndarray of shape (n_features, n_classes)\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoef_ is only available when using a linear kernel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    639\u001b[0m coef \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_coef()\n\u001b[0;32m    641\u001b[0m \u001b[38;5;66;03m# coef_ being a read-only property, it's better to mark the value as\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# immutable to avoid hiding potential bugs for the unsuspecting user.\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: coef_ is only available when using a linear kernel"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importance_svm(model, original_num_features, original_cat_features, X_train):\n",
    "    \"\"\"\n",
    "    Plots a feature importance graph for a trained Support Vector Machine (SVM) model.\n",
    "\n",
    "    Parameters:\n",
    "    model : Trained SVM model (GridSearchCV object)\n",
    "    original_num_features : List of original numerical feature names\n",
    "    original_cat_features : List of original categorical feature names\n",
    "    X_train : Training data (used to fit the preprocessor)\n",
    "    \"\"\"\n",
    "    # Access the pipeline\n",
    "    pipeline = model.best_estimator_\n",
    "\n",
    "    # Extract the preprocessor and SVM model components\n",
    "    preprocessor = pipeline.named_steps['columntransformer']\n",
    "    svm_model = pipeline.named_steps['svc']\n",
    "\n",
    "    # Get the transformed feature names from the preprocessor\n",
    "    # Use `get_feature_names_out` for one-hot encoded features\n",
    "    num_feature_names = original_num_features\n",
    "    cat_feature_names = preprocessor.named_transformers_['onehotencoder'].get_feature_names_out(original_cat_features)\n",
    "\n",
    "    # Combine numerical and one-hot encoded categorical feature names\n",
    "    all_feature_names = np.concatenate([num_feature_names, cat_feature_names])\n",
    "\n",
    "    # Extract coefficients from the SVM model (for linear SVM only)\n",
    "    coefficients = np.abs(svm_model.coef_).flatten()\n",
    "\n",
    "    # Normalize importance to percentage\n",
    "    importance = 100 * (coefficients / np.sum(coefficients))\n",
    "\n",
    "    # Sort features by importance\n",
    "    sorted_idx = np.argsort(importance)[::-1]\n",
    "    sorted_features = all_feature_names[sorted_idx]\n",
    "    sorted_importance = importance[sorted_idx]\n",
    "\n",
    "    # Plot the feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(sorted_features, sorted_importance, color='#F7934C')\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Importance (%)\")\n",
    "    plt.title(\"Feature Importance in SVM\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with necessary arguments\n",
    "plot_feature_importance_svm(grid, num_columns, cat_columns, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
